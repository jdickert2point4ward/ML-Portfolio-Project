{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70be15dc-2939-41cd-a315-fd749f0676fe",
   "metadata": {},
   "source": [
    "# Machine Learning Pipeline for Predictive Safety Risk Classifier\n",
    "\n",
    "This notebook modularizes our ML workflow into a scikit-learn Pipeline, combining preprocessing and the best model (XGBoost) from the previous step. The pipeline ensures reproducibility and ease of deployment.\n",
    "\n",
    "## Dependencies\n",
    "- `pandas`: Data handling.\n",
    "- `scikit-learn`: Pipeline, imputation, and evaluation.\n",
    "- `xgboost`: Best model from workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72d1ab70-a154-4464-9a83-3253392f8263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (24102, 7), Val shape: (5165, 7), Test shape: (5165, 7)\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "\n",
    "# Step 1: Load engineered datasets\n",
    "train_df = pd.read_csv(\"../train_engineered.csv\")\n",
    "val_df = pd.read_csv(\"../val_engineered.csv\")\n",
    "test_df = pd.read_csv(\"../test_engineered.csv\")\n",
    "\n",
    "# Step 2: Split Features and Targets, drop NaNs\n",
    "train_df = train_df.dropna(subset=['Risk'])\n",
    "val_df = val_df.dropna(subset=['Risk'])\n",
    "test_df = test_df.dropna(subset=['Risk'])\n",
    "\n",
    "X_train = train_df.drop(columns=['Risk'])\n",
    "y_train = train_df['Risk']\n",
    "X_val = val_df.drop(columns=['Risk'])\n",
    "y_val = val_df['Risk']\n",
    "X_test = test_df.drop(columns=['Risk'])\n",
    "y_test = test_df['Risk']\n",
    "\n",
    "print(f\"Train shape: {X_train.shape}, Val shape: {X_val.shape}, Test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5e64e4-f519-46c6-9c93-b70cf92fb4d0",
   "metadata": {},
   "source": [
    "## Step 1: Build the Pipeline\n",
    "We create a Pipeline with two steps:\n",
    "1. Imputation to handle any residual NaNs (using zero-fill as in feature engineering).\n",
    "2. XGBoost classifier with tuned parameters from MLWorkflow.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb2d949d-e658-45ca-8c72-cc3ce863399d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline (XGBoost) - Validation Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.98      0.88      4149\n",
      "         1.0       0.25      0.03      0.05      1016\n",
      "\n",
      "    accuracy                           0.79      5165\n",
      "   macro avg       0.53      0.50      0.47      5165\n",
      "weighted avg       0.69      0.79      0.72      5165\n",
      "\n",
      "Accuracy: 0.791\n"
     ]
    }
   ],
   "source": [
    "# Build the Pipeline\n",
    "# Step 1: Define the pipeline steps\n",
    "pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=0)), # Handle any NaNs\n",
    "    (\"classifier\", xgb.XGBClassifier(\n",
    "        max_depth=3,\n",
    "        learning_rate=0.01,\n",
    "        n_estimators=50,\n",
    "        eval_metric=\"logloss\",\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Step 2: Fit the pipeline on training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Step 3: Evaluate on validation set\n",
    "y_val_pred = pipeline.predict(X_val)\n",
    "print(\"Pipeline (XGBoost) - Validation Set Performance:\")\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "print(f\"Accuracy: {accuracy_score(y_val, y_val_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25290b7d-4bcb-4b72-b748-068855e257f1",
   "metadata": {},
   "source": [
    "## Step 2: Final Evaluation\n",
    "Test the pipeline on the held-out test set to confirm generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0060b6a0-080c-4795-9f32-05ac14396a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline (XGBoost) - Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.97      0.88      4150\n",
      "         1.0       0.20      0.03      0.05      1015\n",
      "\n",
      "    accuracy                           0.79      5165\n",
      "   macro avg       0.50      0.50      0.46      5165\n",
      "weighted avg       0.68      0.79      0.72      5165\n",
      "\n",
      "Accuracy: 0.788\n"
     ]
    }
   ],
   "source": [
    "# Final Evaluation on Test Set\n",
    "y_test_pred = pipeline.predict(X_test)\n",
    "print(\"Pipeline (XGBoost) - Test Set Performance:\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_test_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa50be7-dc94-4290-b973-add15978a897",
   "metadata": {},
   "source": [
    "## Step 3: Save the Pipeline\n",
    "Save the entire pipeline (preprocessing + model) for future use or deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06367d31-e91c-4c30-ae80-97df55d97908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline saved as 'safety_risk_pipeline.pk1'\n"
     ]
    }
   ],
   "source": [
    "# Save the Pipeline\n",
    "joblib.dump(pipeline, \"../safety_risk_pipeline.pk1\")\n",
    "print(\"Pipeline saved as 'safety_risk_pipeline.pk1'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e17daf-caa7-4f45-b0a8-fe1ff7573188",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
