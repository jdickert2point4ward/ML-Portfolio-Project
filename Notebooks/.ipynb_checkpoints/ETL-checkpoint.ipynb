{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de11a438-4877-47df-862e-c22f2fa84ae8",
   "metadata": {},
   "source": [
    "# ETL: Extract, Transform, Load for Predictive Safety Risk Classifier\n",
    "\n",
    "This notebook performs the ETL process for our machine learning project, fetching the latest Chicago Crime Dataset via the Socrata API, transforming it with pandas, and saving the result for further analysis.\n",
    "\n",
    "## Prerequisites\n",
    "We’ll install the required `sodapy` library and restart the kernel to ensure a clean environment before proceeding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64104d89-cb26-4116-9232-e4e24aa069f1",
   "metadata": {},
   "source": [
    "## Step 0: Install Dependencies\n",
    "Install the `sodapy` library if it’s not already present in your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55a9727b-bf4d-4ced-bd33-a2815ffcb1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sodapy in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (2.2.0)\n",
      "Requirement already satisfied: requests>=2.28.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from sodapy) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests>=2.28.1->sodapy) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests>=2.28.1->sodapy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests>=2.28.1->sodapy) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jd/Library/Python/3.13/lib/python/site-packages (from requests>=2.28.1->sodapy) (2025.1.31)\n",
      "sodapy installed successfully. Please proceed to the next cell to restart the kernel.\n"
     ]
    }
   ],
   "source": [
    "#Step 0: Install sodapy\n",
    "# - Use pip to install the Socrata API client library\n",
    "# - The ! prefix runs this as a shell command within Jupyter\n",
    "!pip install sodapy\n",
    "\n",
    "print(\"sodapy installed successfully. Please proceed to the next cell to restart the kernel.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7fec7c-97f0-4c14-bf6f-da73497e3541",
   "metadata": {},
   "source": [
    "## Step 1: Restart the Kernel\n",
    "After installing `sodapy`, we restart the kernel to ensure the new library is loaded properly. Run this cell, then manually restart the kernel:\n",
    "- Click \"Kernel\" > \"Restart\" in the Jupyter menu, or press the circular arrow button.\n",
    "- After restarting, continue running the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "559a1c6f-985b-482c-90ea-7e9f90dbcfa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel restarted successfully. Now we can proceed with imports.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Placeholder for kernel restart confirmation\n",
    "# - This cell does nothing but confirm you've restarted the kernel when you run it\n",
    "print(\"Kernel restarted successfully. Now we can proceed with imports.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f707bff5-24ad-4834-a915-3400196eaee6",
   "metadata": {},
   "source": [
    "## Step 2: Import Libraries and Initialize Socrata Client\n",
    "With `sodapy` installed and the kernel refreshed, we import our libraries and set up the API client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fcda26d-8f24-48ad-90cf-62fb83c4b215",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Requests made without an app_token will be subject to strict throttling limits.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will fetch data from 2024-09-01 to 2025-03-01\n"
     ]
    }
   ],
   "source": [
    "#Import libraries and initialize Socrata Client\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sodapy import Socrata\n",
    "from datetime import datetime\n",
    "\n",
    "#Step 1: Setup the Socrata client\n",
    "# - Domain: data.cityofchicago.net\n",
    "# - App token: None (not required for the public data)\n",
    "client = Socrata(\"data.cityofchicago.org\", None)\n",
    "\n",
    "#Step 2: Define the data range for the latest data\n",
    "# - Start: September 1, 2024 (6 months ago from March 2025)\n",
    "# - End: March 1, 2025 (7 days before today, March 7, 2025, per database policy)\n",
    "start_date = \"2024-09-01\"\n",
    "end_date = \"2025-03-01\"\n",
    "print(f\"We will fetch data from {start_date} to {end_date}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56023c6c-db1c-4e16-b281-5bab88942a1a",
   "metadata": {},
   "source": [
    "## Step 3: Extract Data\n",
    "We use the Socrata API to fetch the latest crime data from the Chicago Crime Dataset (ID: ijzp-q8t2). The query limits the data to 50,000 rows to keep the prototype manageable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "739ee86a-407b-4cbd-aa65-990546a218d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial shape: (50000, 22)\n",
      "         id case_number                     date                  block  iucr  \\\n",
      "0  13701180    JH550927  2024-09-01T00:00:00.000       0000X E 117TH PL  1310   \n",
      "1  13700621    JH553061  2024-09-01T00:00:00.000  057XX N MAPLEWOOD AVE  2820   \n",
      "2  13703231    JH556313  2024-09-01T00:00:00.000        033XX W 84TH ST  2825   \n",
      "3  13704073    JH557391  2024-09-01T00:00:00.000  054XX N EAST RIVER RD  1320   \n",
      "4  13707285    JH561154  2024-09-01T00:00:00.000      081XX S DAMEN AVE  0810   \n",
      "\n",
      "      primary_type              description location_description  arrest  \\\n",
      "0  CRIMINAL DAMAGE              TO PROPERTY            APARTMENT   False   \n",
      "1    OTHER OFFENSE         TELEPHONE THREAT            RESIDENCE   False   \n",
      "2    OTHER OFFENSE  HARASSMENT BY TELEPHONE            RESIDENCE   False   \n",
      "3  CRIMINAL DAMAGE               TO VEHICLE            APARTMENT   False   \n",
      "4            THEFT                OVER $500            RESIDENCE   False   \n",
      "\n",
      "   domestic  ... ward community_area fbi_code x_coordinate y_coordinate  year  \\\n",
      "0     False  ...    9             53       14      1178638      1827063  2024   \n",
      "1      True  ...   40              2      08A      1158294      1938051  2024   \n",
      "2     False  ...   18             70       26      1155666      1848699  2024   \n",
      "3     False  ...   41             76       14      1116633      1934807  2024   \n",
      "4     False  ...   17             71       06      1164442      1850680  2024   \n",
      "\n",
      "                updated_on      latitude      longitude  \\\n",
      "0  2024-12-26T15:40:23.000  41.680758108  -87.621727083   \n",
      "1  2024-12-25T15:40:12.000  41.985759177  -87.693169014   \n",
      "2  2024-12-28T15:40:18.000  41.740621127  -87.705238985   \n",
      "3  2024-12-29T15:41:05.000  41.977609479  -87.846467101   \n",
      "4  2025-01-02T15:40:47.000  41.745877018  -87.673028696   \n",
      "\n",
      "                                            location  \n",
      "0  {'latitude': '41.680758108', 'longitude': '-87...  \n",
      "1  {'latitude': '41.985759177', 'longitude': '-87...  \n",
      "2  {'latitude': '41.740621127', 'longitude': '-87...  \n",
      "3  {'latitude': '41.977609479', 'longitude': '-87...  \n",
      "4  {'latitude': '41.745877018', 'longitude': '-87...  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "# Fetch Data from Socrata API\n",
    "# Step 1: Define the query\n",
    "# - Dataset ID: ijzp-q8t2 (Crimes - 2001 to Present)\n",
    "# - Filter: Crimes between start_date and end_date\n",
    "# - Limit: 50,000 rows for prototyping\n",
    "query = f\"date between '{start_date}' and '{end_date}'\"\n",
    "results = client.get(\"ijzp-q8t2\", where=query, limit=50000)\n",
    "\n",
    "# Step 2: Convert results to a pandas DataFrame\n",
    "df = pd.DataFrame.from_records(results)\n",
    "\n",
    "# Step 3: Inspect the initial dataset\n",
    "print(f\"Initial shape: {df.shape}\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff2541e-2f6b-47d7-9f23-bdf3fbbf7d8f",
   "metadata": {},
   "source": [
    "## Step 4: Transform Data (Part 1 - Exploration)\n",
    "Before transforming, we explore the raw data to understand its structure and identify any issues like missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef45872b-0b12-4c12-802b-ce5a5a721706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['id', 'case_number', 'date', 'block', 'iucr', 'primary_type', 'description', 'location_description', 'arrest', 'domestic', 'beat', 'district', 'ward', 'community_area', 'fbi_code', 'x_coordinate', 'y_coordinate', 'year', 'updated_on', 'latitude', 'longitude', 'location']\n",
      "Missing values:\n",
      " id                        0\n",
      "case_number               0\n",
      "date                      0\n",
      "block                     0\n",
      "iucr                      0\n",
      "primary_type              0\n",
      "description               0\n",
      "location_description    153\n",
      "arrest                    0\n",
      "domestic                  0\n",
      "beat                      0\n",
      "district                  0\n",
      "ward                      0\n",
      "community_area            1\n",
      "fbi_code                  0\n",
      "x_coordinate             17\n",
      "y_coordinate             17\n",
      "year                      0\n",
      "updated_on                0\n",
      "latitude                 17\n",
      "longitude                17\n",
      "location                 17\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Explore the Raw Data\n",
    "# Step 1: List available columns\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "\n",
    "#Step 2: Check for missing values\n",
    "print(\"Missing values:\\n\", df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cbba7a-a8cc-49d6-89db-28e571241c5b",
   "metadata": {},
   "source": [
    "## Step 5: Transform Data (Part 2 - Cleaning and Feature Extraction)\n",
    "We clean the data by selecting relevant columns, handling missing values, and extracting time-based features for our safety risk classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1615d054-59c2-4fac-811e-10c70ad93207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after dropping NaNs: (49983, 4)\n",
      "        date   latitude  longitude     primary_type  Hour  DayOfWeek  \\\n",
      "0 2024-09-01  41.680758 -87.621727  CRIMINAL DAMAGE     0          6   \n",
      "1 2024-09-01  41.985759 -87.693169    OTHER OFFENSE     0          6   \n",
      "2 2024-09-01  41.740621 -87.705239    OTHER OFFENSE     0          6   \n",
      "3 2024-09-01  41.977609 -87.846467  CRIMINAL DAMAGE     0          6   \n",
      "4 2024-09-01  41.745877 -87.673029            THEFT     0          6   \n",
      "\n",
      "   IsViolent  \n",
      "0          0  \n",
      "1          0  \n",
      "2          0  \n",
      "3          0  \n",
      "4          0  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 49983 entries, 0 to 49999\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   date          49983 non-null  datetime64[ns]\n",
      " 1   latitude      49983 non-null  float64       \n",
      " 2   longitude     49983 non-null  float64       \n",
      " 3   primary_type  49983 non-null  object        \n",
      " 4   Hour          49983 non-null  int32         \n",
      " 5   DayOfWeek     49983 non-null  int32         \n",
      " 6   IsViolent     49983 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(2), int32(2), int64(1), object(1)\n",
      "memory usage: 2.7+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Clean and Transform the Data\n",
    "# Step 1: Select relevant columns\n",
    "columns = [\"date\", \"latitude\", \"longitude\", \"primary_type\"]\n",
    "df = df[columns].copy()\n",
    "\n",
    "# Step 2: Convert latitude/longitude to numeric and drop rows with missing coordinates\n",
    "df[\"latitude\"] = pd.to_numeric(df[\"latitude\"], errors=\"coerce\")\n",
    "df[\"longitude\"] = pd.to_numeric(df[\"longitude\"], errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"latitude\", \"longitude\"])\n",
    "print(f\"Shape after dropping NaNs: {df.shape}\")\n",
    "\n",
    "# Step 3: Convert date to datetime and extract features\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df[\"Hour\"] = df[\"date\"].dt.hour\n",
    "df[\"DayOfWeek\"] = df[\"date\"].dt.dayofweek # 0 = Monday, 6 = Sunday\n",
    "\n",
    "# Step 4: Add a feature for violent crimes\n",
    "violent_crimes = [\"HOMICIDE\", \"ASSAULT\", \"BATTERY\", \"ROBBERY\", \"CRIM SEXUAL ASSAULT\"]\n",
    "df[\"IsViolent\"] = df[\"primary_type\"].isin(violent_crimes).astype(int)\n",
    "\n",
    "# Step 5: Verify the transformed data\n",
    "print(df.head())\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047dfa30-f685-49b1-8011-e87222aba11a",
   "metadata": {},
   "source": [
    "## Step 6: Transform Data (Part 3 - Aggregation)\n",
    "We aggregate crimes by location to create our target variable (Risk) for the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5eeefd0b-219d-4816-a5eb-9978952e7bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    latitude  longitude  CrimeCount  ViolentCount  Risk\n",
      "0  41.644604 -87.610728           1             0     0\n",
      "1  41.644608 -87.598848           1             0     0\n",
      "2  41.645378 -87.540022           1             0     0\n",
      "3  41.646123 -87.542896           1             0     0\n",
      "4  41.647038 -87.616003           1             1     0\n",
      "Risk distribution:\n",
      "Risk\n",
      "0    27661\n",
      "1     6771\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Aggregate by Location and Define Risk\n",
    "# Step 1: Group by latitude and longitude\n",
    "location_counts = df.groupby([\"latitude\", \"longitude\"]).agg (\n",
    "    CrimeCount = (\"primary_type\", \"count\"),\n",
    "    ViolentCount = (\"IsViolent\", \"sum\")\n",
    ").reset_index()\n",
    "\n",
    "# Step 2: Define the Risk label\n",
    "# - High-risk (1): Crime count above median\n",
    "# - Low-risk (0): Crim count at or below median\n",
    "median_count = location_counts[\"CrimeCount\"].median()\n",
    "location_counts[\"Risk\"] = (location_counts[\"CrimeCount\"] > median_count).astype(int)\n",
    "\n",
    "# Step 3: Inspect the aggrageted data\n",
    "print(location_counts.head())\n",
    "print(f\"Risk distribution:\\n{location_counts['Risk'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6567859f-f2fb-4c46-836e-af7f3908270d",
   "metadata": {},
   "source": [
    "## Step 7: Load the Transformed Data\n",
    "We save the transformed dataset as a CSV file for use in feature engineering and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a5a3ab6-1b09-4adc-948c-dc71984ce728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed dataset saved as 'chicago_crimes_latest_transformed.csv'\n"
     ]
    }
   ],
   "source": [
    "#Save the Transformed Dataset\n",
    "# Step 1: Export to CSV\n",
    "location_counts.to_csv(\"chicago_crimes_latest_transformed.csv\", index=False)\n",
    "\n",
    "# Step 2: Confirm completion\n",
    "print(\"Transformed dataset saved as 'chicago_crimes_latest_transformed.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a16098-33f1-4155-a32c-638c405a7df0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
